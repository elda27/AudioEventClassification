{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def round_even(x):\n",
    "    if x % 2 == 0:\n",
    "        return x + 1\n",
    "    else:\n",
    "        return x + 2\n",
    "    \n",
    "class ConvRegressor(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, filters, kernel_size, \n",
    "        conv_type=tf.keras.layers.Conv2D, activation=tf.nn.relu, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.conv_type = conv_type\n",
    "        self.convs = []\n",
    "        for n_filter in filters:\n",
    "            self.convs.append(\n",
    "                conv_type(n_filter, round_even(kernel_size), strides=2, padding='SAME', activation=activation, **kwargs)\n",
    "            )\n",
    "            self.convs.append(conv_type(n_filter, kernel_size, padding='SAME', activation=activation, **kwargs))\n",
    "        self.convs.append(tf.keras.layers.Conv2D(n_filter, kernel_size, padding='SAME'))\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, training=False):\n",
    "        y = x\n",
    "        for conv in self.convs:\n",
    "            y = conv(y, training=training)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from libs.layers import resnet\n",
    "from libs.layers import cbam_resnet\n",
    "from libs.layers import conv_attention_resnet\n",
    "\n",
    "ResNet = resnet.ResNet34\n",
    "ResNetCBAM = cbam_resnet.ResNetCBAM34\n",
    "AttentionResNet = conv_attention_resnet.AttentionResNet34\n",
    "AxialAttentionResNet = conv_attention_resnet.AxialAttentionResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "fold_index = 0\n",
    "task = 'home'\n",
    "model_type = 'attention'\n",
    "\n",
    "model_dir = './model'\n",
    "data_dir = './data'\n",
    "\n",
    "save_without_train = True\n",
    "allow_memory_growth = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(\n",
    "    tf.config.list_physical_devices('GPU')[0], allow_memory_growth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "model_dir = Path(model_dir)\n",
    "data_dir = Path(data_dir)\n",
    "model_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c204d33b7d4cdcbd3c35401772de1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load training setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from libs.misc import wavio\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "root_dir = data_dir / 'evaluation_setup'\n",
    "\n",
    "data_cache = {}\n",
    "\n",
    "def get_annotation(task, fold_index, target):\n",
    "    df = pd.read_csv(\n",
    "        root_dir / f'{task}_fold{fold_index+1}_{target}.txt', sep='\\t', \n",
    "        header=None, names=['file', 'class', 'start', 'end', 'event']\n",
    "    )\n",
    "    df['id'] = df['file'].apply(lambda x: Path(x).stem)\n",
    "    return df\n",
    "\n",
    "def load_dataset(target):\n",
    "    if target not in data_cache:\n",
    "        df = get_annotation(task, fold_index, target)\n",
    "        wav_dict = {}\n",
    "        for file in tqdm(df['file'].unique()):\n",
    "            wav_dict[Path(file).stem] = wavio.readwav(str(data_dir / file))\n",
    "        data_cache[target] = (df, wav_dict)\n",
    "        return df, wav_dict\n",
    "    else:\n",
    "        return data_cache[target]\n",
    "df, wav_dict = load_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(object) rustling' '(object) snapping' 'cupboard' 'cutlery' 'dishes'\n",
      " 'drawer' 'glass jingling' 'nan' 'object impact' 'people walking'\n",
      " 'washing dishes' 'water tap running']\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "sound_events = []\n",
    "\n",
    "for fold, task_name in product([0,1,2,3], ['train', 'evaluate', 'test']):\n",
    "    sound_events.extend(get_annotation('home', fold, task_name)['event'].unique())\n",
    "sound_events = np.unique(sound_events)\n",
    "print(sound_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "n_augmentation = 5\n",
    "perturbation = (0.0, 0.05)\n",
    "\n",
    "def parse_wave(series, wav_dict, perturbation=(0.0, 0.0), offset=0.0):\n",
    "    sp, ep = np.random.normal(loc=perturbation[0], scale=perturbation[1], size=2)\n",
    "    \n",
    "    result = series.to_dict()\n",
    "    sr, bw, audio = wav_dict[series['id']]\n",
    "    result['start_perturbation'] = sp\n",
    "    result['end_perturbation'] = ep\n",
    "    \n",
    "    start = int((series['start'] - sp + offset) * sr)\n",
    "    end = int((series['end'] + ep + offset) * sr)\n",
    "    result['start_index'] = max(start, 0)\n",
    "    result['end_index'] = min(end, len(audio))\n",
    "    result['sr'] = sr\n",
    "    result['bw'] = bw\n",
    "    result['audio'] = audio[result['start_index']:result['end_index']]\n",
    "    return pd.Series(result)\n",
    "\n",
    "def parse_wave_multiple(series, wav_dict, window_size, hop_size, perturbation=(0.0, 0.0)):\n",
    "    dt = series['end'] - series['start']\n",
    "    result = []\n",
    "    if dt > window_size:\n",
    "        for start in np.arange(0, dt, hop_size):\n",
    "            if start + window_size > dt:\n",
    "                break\n",
    "            result.append(parse_wave(series, wav_dict, perturbation, offset=start))\n",
    "    else:\n",
    "        result.append(parse_wave(series, wav_dict, perturbation=perturbation))\n",
    "    return result        \n",
    "\n",
    "def parse_wave_with_augmentation(series, wav_dict, n_augmentation, with_multiple=False, **kwargs):\n",
    "    if with_multiple:\n",
    "        result = []\n",
    "        for i in range(n_augmentation):\n",
    "            result.extend(parse_wave_multiple(series, wav_dict, perturbation=perturbation, **kwargs))\n",
    "        df = pd.DataFrame(result)\n",
    "        df['original_index'] = series.name\n",
    "    else:\n",
    "        df = pd.DataFrame([\n",
    "            parse_wave(series, wav_dict, perturbation=perturbation)\n",
    "            for i in range(n_augmentation)\n",
    "        ])\n",
    "        df['original_index'] = series.name\n",
    "    return df\n",
    "\n",
    "_id = df.loc[0, 'id']\n",
    "sr = wav_dict[_id][0]\n",
    "# display(Audio(wav_dict[_id][2][:, 0], rate=sr))\n",
    "# display(Audio(\n",
    "#     parse_wave(df.loc[0], wav_dict=wav_dict)['audio'][:, 0], rate=sr\n",
    "# ))\n",
    "# audio_df = df.apply(partial(parse_wave, wav_dict=wav_dict, window_size=5.0, hop_size=1.25), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import librosa\n",
    "\n",
    "n_mels = 128\n",
    "n_sampling=4096\n",
    "hop_length = n_sampling // 4\n",
    "window='hann'\n",
    "pad='constant'\n",
    "max_time = 1.0\n",
    "batch_size = 2\n",
    "\n",
    "def preprocess(wav, sampling_rate):\n",
    "    return np.concatenate([\n",
    "        mono_preprocess(wav[..., 0], sampling_rate)[..., np.newaxis],\n",
    "        mono_preprocess(wav[..., 1], sampling_rate)[..., np.newaxis],\n",
    "    ], axis=-1)\n",
    "    \n",
    "def mono_preprocess(wav, sampling_rate):\n",
    "#     F = librosa.stft(wav, n_sampling, hop_length=hopsize, window=window, pad_mode=pad)\n",
    "#     mag = np.abs(F)[..., np.newaxis]\n",
    "#     phase = np.angle(F)[..., np.newaxis]\n",
    "#     mag_phase = np.concatenate([mag, phase], axis=2)\n",
    "    \n",
    "    mag = librosa.feature.melspectrogram(\n",
    "        wav, sr=sampling_rate, hop_length=hop_length, n_mels=n_mels,\n",
    "        fmin=0.0, fmax=20e3,\n",
    "    )\n",
    "    logmag = np.log(mag + 1e8)\n",
    "    return logmag\n",
    "\n",
    "def normalize_time(audio_df, max_time):\n",
    "    results = []\n",
    "    for audio, sr in zip(audio_df['audio'], audio_df['sr']):\n",
    "        max_len = int(sr * max_time)\n",
    "\n",
    "        pos = min(len(audio), max_len)\n",
    "        result = np.zeros((max_len, 2), np.float32)\n",
    "        result[:pos, :] = audio[:pos]\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_dataset(target, n_augmentation=1, with_original=False):\n",
    "    df, wav_dict = load_dataset(target)\n",
    "    if n_augmentation != 1:\n",
    "        audio_df = df.groupby(level=0).apply(\n",
    "            lambda df: parse_wave_with_augmentation(\n",
    "                df.iloc[0],\n",
    "                wav_dict=wav_dict, n_augmentation=n_augmentation,\n",
    "            )\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        results = []\n",
    "        for i in range(len(df)):\n",
    "            results.extend(\n",
    "                parse_wave_multiple(\n",
    "                    df.loc[i], wav_dict=wav_dict, window_size=max_time, \n",
    "                    hop_size=max_time / 4\n",
    "                )\n",
    "            )\n",
    "        audio_df = pd.DataFrame(results)\n",
    "\n",
    "    encoding_dict = {c: i for i, c in enumerate(sound_events)}\n",
    "\n",
    "    normed_audio = normalize_time(audio_df, max_time=5.0)\n",
    "    audios = np.concatenate([\n",
    "        preprocess(audio, sr)[np.newaxis] \n",
    "        for audio, sr in tqdm(zip(normed_audio, audio_df['sr']), total=len(normed_audio))\n",
    "    ], axis=0)\n",
    "    \n",
    "    events = audio_df['event'].replace({\n",
    "        event: i for i, event in enumerate(sound_events)\n",
    "    })\n",
    "    if with_original:\n",
    "        return (\n",
    "            audios.astype(np.float32), \n",
    "            np.array([audio for audio in normed_audio]).astype(np.float32),\n",
    "            events.to_numpy().astype(np.int32),\n",
    "        )\n",
    "    else:\n",
    "        return audios.astype(np.float32), events.to_numpy().astype(np.int32)\n",
    "\n",
    "def get_tf_dataset(target, batch_size=32, shuffle=False, **kwargs):\n",
    "    data = get_dataset(target, **kwargs)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(data).batch(\n",
    "        batch_size, drop_remainder=shuffle)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8246826ac754462b44f469cb591000b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1885.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8352ae19c9fc4013b641fb639a0c5541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80519d86bb440f8a52727528f52e4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1046.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = get_tf_dataset('train', batch_size=batch_size, n_augmentation=1, with_original=True)\n",
    "test_dataset = get_tf_dataset('evaluate', batch_size=batch_size, with_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class PlotCallback(tf.keras.callbacks.Callback):\n",
    "    is_higher_better = {\n",
    "        'accuracy'\n",
    "    }\n",
    "    is_linear = {\n",
    "        'accuracy',\n",
    "        'sparse_categorical_accuracy',\n",
    "    }\n",
    "    def __init__(self, targets=None, n_step=1):\n",
    "        super().__init__()\n",
    "        self.fig = None\n",
    "        self.axes = None\n",
    "        self.axes_index = {}\n",
    "        self.n_step = n_step\n",
    "        self.targets = targets\n",
    "        self.epochs = []\n",
    "        self.history = defaultdict(list)\n",
    "\n",
    "    def plot_and_display(self):\n",
    "        for ax in self.axes.flat:\n",
    "            ax.clear()\n",
    "        for i, (label, values) in enumerate(self.history.items()):\n",
    "            if any(name in label for name in self.is_higher_better):\n",
    "                get_best_value = np.amax\n",
    "            else:\n",
    "                get_best_value = np.amin\n",
    "            \n",
    "            if label.startswith('val_'):\n",
    "                _label = label[4:]\n",
    "            else:\n",
    "                _label = label\n",
    "            \n",
    "            ax = self.axes.flat[self.axes_index[_label]]\n",
    "            ax.plot(self.epochs, values, label=label, color=f'C{i}')\n",
    "            best_value = get_best_value(values)\n",
    "            ax.axhline(best_value, linestyle='--', color=f'C{i}')\n",
    "            ax.text(0.0, best_value, f'{best_value:.3f}')\n",
    "            \n",
    "            if _label not in self.is_linear:\n",
    "                ax.set_yscale('log')\n",
    "\n",
    "        if self.epochs[-1] == 0:\n",
    "            self.fig.legend()\n",
    "\n",
    "        io = BytesIO()\n",
    "        self.fig.savefig(io, format='png')\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display_png(Image(io.getvalue()))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch == 0:\n",
    "            self.fig, self.axes = plt.subplots(len(logs) // 2, 1, figsize=(8, 4 * len(logs) // 2))\n",
    "            self.axes_index = {}\n",
    "            for label in logs:\n",
    "                if label.startswith('val_'):\n",
    "                    _label = label[4:]\n",
    "                else:\n",
    "                    _label = label\n",
    "                if _label not in self.axes_index:\n",
    "                    self.axes_index[_label] = len(self.axes_index)\n",
    "\n",
    "        for key, value in logs.items():\n",
    "            self.history[key].append(value)\n",
    "\n",
    "        self.epochs.append(epoch)\n",
    "        if (epoch % self.n_step) == 0:\n",
    "            self.plot_and_display()\n",
    "\n",
    "class BalancedSparseCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "    def __init__(self, name='balanced_sparse_categorical_accuracy', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_flat = y_true\n",
    "        if y_true.shape.ndims == y_pred.shape.ndims:\n",
    "            y_flat = tf.squeeze(y_flat, axis=[-1])\n",
    "        y_true_int = tf.cast(y_flat, tf.int32)\n",
    "\n",
    "        cls_counts = tf.math.bincount(y_true_int)\n",
    "        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n",
    "        weight = tf.gather(cls_counts, y_true_int)\n",
    "        return super().update_state(y_true, y_pred, sample_weight=weight)\n",
    "    \n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    return tf.keras.Sequential([\n",
    "        ConvRegressor([8, 16, 32, 64, 128, 256], kernel_size=7),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "def create_resnet_cnn_model():\n",
    "    return tf.keras.Sequential([\n",
    "        ResNet(kernel_size=5),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "def create_cbam_model():\n",
    "    return tf.keras.Sequential([\n",
    "        ResNetCBAM(kernel_size=5),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "def create_attention_model():\n",
    "    return tf.keras.Sequential([\n",
    "        AttentionResNet(kernel_size=1),\n",
    "        tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "def create_axial_attention_model():\n",
    "    return tf.keras.Sequential([\n",
    "        AxialAttentionResNet(kernel_size=1),\n",
    "        tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "model_type = 'attention'\n",
    "if model_type == 'cnn':\n",
    "    learning_rate = 1e-4\n",
    "    create_model = create_cnn_model\n",
    "elif model_type == 'resnet':\n",
    "    learning_rate = 1e-4\n",
    "    create_model = create_resnet_cnn_model\n",
    "elif model_type == 'cbam':\n",
    "    learning_rate = 1e-4\n",
    "    create_model = create_cbam_model\n",
    "elif model_type == 'attention':\n",
    "    create_model = create_attention_model\n",
    "    learning_rate = CustomSchedule(128)\n",
    "elif model_type == 'axial-attention':\n",
    "    learning_rate = 1e-4\n",
    "    create_model = create_axial_attention_model\n",
    "else:\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = tf.keras.Sequential([\n",
    "#         AttentionResNet(kernel_size=1),\n",
    "#         tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "#         tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "#         tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "# ])\n",
    "# print(net(np.zeros((4, 128, 216, 2), dtype=np.float32)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "243/943 [======>.......................] - ETA: 4:01 - loss: 3.3924 - balanced_sparse_categorical_accuracy: 0.6074"
     ]
    }
   ],
   "source": [
    "import IPython \n",
    "from collections import defaultdict \n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import time\n",
    "import seaborn as sns\n",
    "from io import BytesIO\n",
    "import imageio\n",
    "from IPython.display import Image, display_png, clear_output\n",
    "\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "if 'model' in globals():\n",
    "    del model\n",
    "epochs = 2000\n",
    "model = create_model()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.5, beta_2=0.99)\n",
    "\n",
    "checkpoint_name = f'{task}_cnn_{model_type}_fold{fold_index}'\n",
    "cur_model_dir = model_dir / checkpoint_name\n",
    "cur_model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "plot_callback = PlotCallback(n_step=3)\n",
    "with tf.device('/GPU:0'):\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction=tf.keras.losses.Reduction.SUM),\n",
    "        optimizer=optimizer,\n",
    "        metrics=BalancedSparseCategoricalAccuracy(),\n",
    "#         options=tf.distribute.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "    )\n",
    "    \n",
    "    mode = 'max'\n",
    "    model.fit(\n",
    "        train_dataset.map(lambda *vars_list: (vars_list[0], vars_list[-1])),\n",
    "        batch_size=batch_size, epochs=2000, shuffle=True,\n",
    "        validation_data=test_dataset.map(lambda *vars_list: (vars_list[0], vars_list[-1])),\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                patience=10, \n",
    "                #monitor='val_sparse_categorical_accuracy',\n",
    "                monitor='val_balanced_sparse_categorical_accuracy',\n",
    "                mode=mode\n",
    "            ),\n",
    "            plot_callback,\n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                str(cur_model_dir / (checkpoint_name + '.model')),\n",
    "                monitor='val_balanced_sparse_categorical_accuracy', \n",
    "#                 monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True,\n",
    "                mode=mode, \n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "plot_callback.fig.tight_layout()\n",
    "plot_callback.fig.savefig(str(cur_model_dir / (checkpoint_name + '.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_data = []\n",
    "model = create_model()\n",
    "model.load_weights(str(cur_model_dir / (checkpoint_name + '.model')))\n",
    "model.compile()\n",
    "\n",
    "results = {}\n",
    "for target_name, dataset in zip(['train', 'test'], (train_dataset, test_dataset)):\n",
    "    pred_logits = model.predict(\n",
    "        dataset.map(lambda audios, norm_audios, labels: (audios, labels))\n",
    "    )\n",
    "    pred_labels = tf.argmax(tf.nn.softmax(pred_logits, axis=1), axis=1)\n",
    "    \n",
    "    audio = []\n",
    "    truth_labels = []\n",
    "    for batch in dataset:\n",
    "        audio.extend(batch[1].numpy())\n",
    "        truth_labels.extend(batch[2].numpy())\n",
    "    metric = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(\n",
    "        tf.convert_to_tensor(np.array(truth_labels).astype(np.int32)), \n",
    "        tf.convert_to_tensor(pred_logits.astype(np.float32))\n",
    "    )).numpy()\n",
    "\n",
    "    truth_labels = np.array(sound_events).take(truth_labels)\n",
    "    pred_labels = np.array(sound_events).take(pred_labels)\n",
    "    \n",
    "    agg_df = pd.crosstab(\n",
    "        pd.Series(truth_labels, name='Truth'),\n",
    "        pd.Series(pred_labels, name='Prediction'),\n",
    "    )\n",
    "    agg_df = agg_df.reindex(columns=sound_events, index=sound_events, fill_value=0)\n",
    "    display(target_name)\n",
    "    display(agg_df)\n",
    "    \n",
    "    accuracy = {}\n",
    "    for name in sound_events:\n",
    "        mask = truth_labels == name\n",
    "        accuracy[name] = accuracy_score(truth_labels[mask], pred_labels[mask]) \n",
    "    accuracy['Metric'] = metric\n",
    "    accuracy_data.append(pd.Series(accuracy, name=target_name))\n",
    "    \n",
    "    results[target_name] = {\n",
    "        'Audio': None if save_without_train and target_name == 'train' else audio,\n",
    "        'Prediction': pd.DataFrame({\n",
    "            'Prediction': pred_labels,\n",
    "            'Truth': truth_labels,\n",
    "        }),\n",
    "        'Agg': agg_df,\n",
    "        'Accuracy': accuracy_data,\n",
    "    }\n",
    "accuracy_df = pd.DataFrame(accuracy_data)\n",
    "accuracy_df['Mean'] = accuracy_df.mean(axis=1)\n",
    "display(accuracy_df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle as pickle\n",
    "with open(cur_model_dir / f'result_metric.pickle', 'wb+') as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_without_train and 'train' == 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
