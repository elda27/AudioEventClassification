{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def round_even(x):\n",
    "    if x % 2 == 0:\n",
    "        return x + 1\n",
    "    else:\n",
    "        return x + 2\n",
    "    \n",
    "class ConvRegressor(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, filters, kernel_size, \n",
    "        conv_type=tf.keras.layers.Conv2D, activation=tf.nn.relu, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.conv_type = conv_type\n",
    "        self.convs = []\n",
    "        for n_filter in filters:\n",
    "            self.convs.append(\n",
    "                conv_type(n_filter, round_even(kernel_size), strides=2, padding='SAME', activation=activation, **kwargs)\n",
    "            )\n",
    "            self.convs.append(conv_type(n_filter, kernel_size, padding='SAME', activation=activation, **kwargs))\n",
    "        self.convs.append(tf.keras.layers.Conv2D(n_filter, kernel_size, padding='SAME'))\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, training=False):\n",
    "        y = x\n",
    "        for conv in self.convs:\n",
    "            y = conv(y, training=training)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from libs.layers import resnet\n",
    "from libs.layers import cbam_resnet\n",
    "\n",
    "ResNet101 = resnet.ResNet101\n",
    "ResNetCBAM101 = cbam_resnet.ResNetCBAM101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "fold_index = 0\n",
    "task = 'home'\n",
    "model_type = 'cbam'\n",
    "\n",
    "model_dir = './model'\n",
    "data_dir = './data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "model_dir = Path(model_dir)\n",
    "data_dir = Path(data_dir)\n",
    "model_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from libs.misc import wavio\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "root_dir = data_dir / 'evaluation_setup'\n",
    "\n",
    "def get_annotation(task, fold_index, target):\n",
    "    df = pd.read_csv(\n",
    "        root_dir / f'{task}_fold{fold_index+1}_{target}.txt', sep='\\t', \n",
    "        header=None, names=['file', 'class', 'start', 'end', 'event']\n",
    "    )\n",
    "    df['id'] = df['file'].apply(lambda x: Path(x).stem)\n",
    "    return df\n",
    "\n",
    "def load_dataset(target):\n",
    "    df = get_annotation(task, fold_index, target)\n",
    "    wav_dict = {}\n",
    "    for file in tqdm(df['file'].unique()):\n",
    "        wav_dict[Path(file).stem] = wavio.readwav(str(data_dir / file))\n",
    "    return df, wav_dict\n",
    "\n",
    "df, wav_dict = load_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "sound_events = []\n",
    "\n",
    "for fold, task_name in product([0,1,2,3], ['train', 'evaluate', 'test']):\n",
    "    sound_events.extend(get_annotation('home', fold, task_name)['event'].unique())\n",
    "sound_events = np.unique(sound_events)\n",
    "print(sound_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "n_augmentation = 5\n",
    "perturbation = (0.0, 0.05)\n",
    "\n",
    "def parse_wave(series, wav_dict, perturbation=(0.0, 0.0), offset=0.0):\n",
    "    sp, ep = np.random.normal(loc=perturbation[0], scale=perturbation[1], size=2)\n",
    "    \n",
    "    result = series.to_dict()\n",
    "    sr, bw, audio = wav_dict[series['id']]\n",
    "    result['start_perturbation'] = sp\n",
    "    result['end_perturbation'] = ep\n",
    "    \n",
    "    start = int((series['start'] - sp + offset) * sr)\n",
    "    end = int((series['end'] + ep + offset) * sr)\n",
    "    result['start_index'] = max(start, 0)\n",
    "    result['end_index'] = min(end, len(audio))\n",
    "    result['sr'] = sr\n",
    "    result['bw'] = bw\n",
    "    result['audio'] = audio[result['start_index']:result['end_index']]\n",
    "    return pd.Series(result)\n",
    "\n",
    "def parse_wave_multiple(series, wav_dict, window_size, hop_size, perturbation=(0.0, 0.0)):\n",
    "    dt = series['end'] - series['start']\n",
    "    result = []\n",
    "    if dt > window_size:\n",
    "        for start in np.arange(0, dt, hop_size):\n",
    "            if start + window_size > dt:\n",
    "                break\n",
    "            result.append(parse_wave(series, wav_dict, perturbation, offset=start))\n",
    "    else:\n",
    "        result.append(parse_wave(series, wav_dict, perturbation=perturbation))\n",
    "    return result        \n",
    "\n",
    "def parse_wave_with_augmentation(series, wav_dict, n_augmentation, with_multiple=False, **kwargs):\n",
    "    if with_multiple:\n",
    "        result = []\n",
    "        for i in range(n_augmentation):\n",
    "            result.extend(parse_wave_multiple(series, wav_dict, perturbation=perturbation, **kwargs))\n",
    "        df = pd.DataFrame(result)\n",
    "        df['original_index'] = series.name\n",
    "    else:\n",
    "        df = pd.DataFrame([\n",
    "            parse_wave(series, wav_dict, perturbation=perturbation)\n",
    "            for i in range(n_augmentation)\n",
    "        ])\n",
    "        df['original_index'] = series.name\n",
    "    return df\n",
    "\n",
    "_id = df.loc[0, 'id']\n",
    "sr = wav_dict[_id][0]\n",
    "# display(Audio(wav_dict[_id][2][:, 0], rate=sr))\n",
    "# display(Audio(\n",
    "#     parse_wave(df.loc[0], wav_dict=wav_dict)['audio'][:, 0], rate=sr\n",
    "# ))\n",
    "# audio_df = df.apply(partial(parse_wave, wav_dict=wav_dict, window_size=5.0, hop_size=1.25), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import librosa\n",
    "\n",
    "n_mels = 128\n",
    "n_sampling=4096\n",
    "hop_length = n_sampling // 4\n",
    "window='hann'\n",
    "pad='constant'\n",
    "max_time = 1.0\n",
    "\n",
    "def preprocess(wav, sampling_rate):\n",
    "    return np.concatenate([\n",
    "        mono_preprocess(wav[..., 0], sampling_rate)[..., np.newaxis],\n",
    "        mono_preprocess(wav[..., 1], sampling_rate)[..., np.newaxis],\n",
    "    ], axis=-1)\n",
    "    \n",
    "def mono_preprocess(wav, sampling_rate):\n",
    "#     F = librosa.stft(wav, n_sampling, hop_length=hopsize, window=window, pad_mode=pad)\n",
    "#     mag = np.abs(F)[..., np.newaxis]\n",
    "#     phase = np.angle(F)[..., np.newaxis]\n",
    "#     mag_phase = np.concatenate([mag, phase], axis=2)\n",
    "    \n",
    "    mag = librosa.feature.melspectrogram(\n",
    "        wav, sr=sampling_rate, hop_length=hop_length, n_mels=n_mels,\n",
    "        fmin=0.0, fmax=20e3,\n",
    "    )\n",
    "    logmag = np.log(mag + 1e8)\n",
    "    return logmag\n",
    "\n",
    "def normalize_time(audio_df, max_time):\n",
    "    results = []\n",
    "    for audio, sr in zip(audio_df['audio'], audio_df['sr']):\n",
    "        max_len = int(sr * max_time)\n",
    "\n",
    "        pos = min(len(audio), max_len)\n",
    "        result = np.zeros((max_len, 2), np.float32)\n",
    "        result[:pos, :] = audio[:pos]\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_dataset(target, n_augmentation=1):\n",
    "    df, wav_dict = load_dataset(target)\n",
    "    if n_augmentation != 1:\n",
    "        audio_df = df.groupby(level=0).apply(\n",
    "            lambda df: parse_wave_with_augmentation(\n",
    "                df.iloc[0],\n",
    "                wav_dict=wav_dict, n_augmentation=n_augmentation,\n",
    "            )\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        results = []\n",
    "        for i in range(len(df)):\n",
    "            results.extend(\n",
    "                parse_wave_multiple(\n",
    "                    df.loc[i], wav_dict=wav_dict, window_size=max_time, \n",
    "                    hop_size=max_time / 4\n",
    "                )\n",
    "            )\n",
    "        audio_df = pd.DataFrame(results)\n",
    "\n",
    "    encoding_dict = {c: i for i, c in enumerate(sound_events)}\n",
    "\n",
    "    normed_audio = normalize_time(audio_df, max_time=5.0)\n",
    "    audios = np.concatenate([\n",
    "        preprocess(audio, sr)[np.newaxis] \n",
    "        for audio, sr in tqdm(zip(normed_audio, audio_df['sr']), total=len(normed_audio))\n",
    "    ], axis=0)\n",
    "    \n",
    "    events = audio_df['event'].replace({\n",
    "        event: i for i, event in enumerate(sound_events)\n",
    "    })\n",
    "    \n",
    "    return audios.astype(np.float32), events.to_numpy().astype(np.int32)\n",
    "\n",
    "def get_tf_dataset(target, batch_size=32, shuffle=False, **kwargs):\n",
    "    audio, events = get_dataset(target, **kwargs)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((audio, events)).batch(\n",
    "        batch_size, drop_remainder=shuffle)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_tf_dataset('train', batch_size=32, n_augmentation=1)\n",
    "test_dataset = get_tf_dataset('evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class PlotCallback(tf.keras.callbacks.Callback):\n",
    "    is_higher_better = {\n",
    "        'accuracy'\n",
    "    }\n",
    "    is_linear = {\n",
    "        'accuracy',\n",
    "        'sparse_categorical_accuracy',\n",
    "    }\n",
    "    def __init__(self, targets=None, n_step=1):\n",
    "        super().__init__()\n",
    "        self.fig = None\n",
    "        self.axes = None\n",
    "        self.axes_index = {}\n",
    "        self.n_step = n_step\n",
    "        self.targets = targets\n",
    "        self.epochs = []\n",
    "        self.history = defaultdict(list)\n",
    "\n",
    "    def plot_and_display(self):\n",
    "        for ax in self.axes.flat:\n",
    "            ax.clear()\n",
    "        for i, (label, values) in enumerate(self.history.items()):\n",
    "            if any(name in label for name in self.is_higher_better):\n",
    "                get_best_value = np.amax\n",
    "            else:\n",
    "                get_best_value = np.amin\n",
    "            \n",
    "            if label.startswith('val_'):\n",
    "                _label = label[4:]\n",
    "            else:\n",
    "                _label = label\n",
    "            \n",
    "            ax = self.axes.flat[self.axes_index[_label]]\n",
    "            ax.plot(self.epochs, values, label=label, color=f'C{i}')\n",
    "            best_value = get_best_value(values)\n",
    "            ax.axhline(best_value, linestyle='--', color=f'C{i}')\n",
    "            ax.text(0.0, best_value, f'{best_value:.3f}')\n",
    "            \n",
    "            if _label not in self.is_linear:\n",
    "                ax.set_yscale('log')\n",
    "\n",
    "        if self.epochs[-1] == 0:\n",
    "            self.fig.legend()\n",
    "\n",
    "        io = BytesIO()\n",
    "        self.fig.savefig(io, format='png')\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display_png(Image(io.getvalue()))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch == 0:\n",
    "            self.fig, self.axes = plt.subplots(len(logs) // 2, 1, figsize=(8, 4 * len(logs) // 2))\n",
    "            self.axes_index = {}\n",
    "            for label in logs:\n",
    "                if label.startswith('val_'):\n",
    "                    _label = label[4:]\n",
    "                else:\n",
    "                    _label = label\n",
    "                if _label not in self.axes_index:\n",
    "                    self.axes_index[_label] = len(self.axes_index)\n",
    "\n",
    "        for key, value in logs.items():\n",
    "            self.history[key].append(value)\n",
    "\n",
    "        self.epochs.append(epoch)\n",
    "        if (epoch % self.n_step) == 0:\n",
    "            self.plot_and_display()\n",
    "\n",
    "class BalancedSparseCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "    def __init__(self, name='balanced_sparse_categorical_accuracy', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_flat = y_true\n",
    "        if y_true.shape.ndims == y_pred.shape.ndims:\n",
    "            y_flat = tf.squeeze(y_flat, axis=[-1])\n",
    "        y_true_int = tf.cast(y_flat, tf.int32)\n",
    "\n",
    "        cls_counts = tf.math.bincount(y_true_int)\n",
    "        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n",
    "        weight = tf.gather(cls_counts, y_true_int)\n",
    "        return super().update_state(y_true, y_pred, sample_weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = next(train_dataset.as_numpy_iterator())[0].shape\n",
    "print(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    return tf.keras.Sequential([\n",
    "        ConvRegressor([8, 16, 32, 64, 128, 256], kernel_size=7),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "def create_resnet_cnn_model():\n",
    "    return tf.keras.Sequential([\n",
    "        ResNet101(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "def create_cbam_model():\n",
    "    return tf.keras.Sequential([\n",
    "        ResNetCBAM101(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "if model_type == 'cnn':\n",
    "    create_model = create_cnn_model\n",
    "elif model_type == 'resnet':\n",
    "    create_model = create_resnet_cnn_model\n",
    "elif model_type == 'cbam':\n",
    "    create_model = create_cbam_model\n",
    "else:\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython \n",
    "from collections import defaultdict \n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import time\n",
    "import seaborn as sns\n",
    "from io import BytesIO\n",
    "import imageio\n",
    "from IPython.display import Image, display_png, clear_output\n",
    "\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "epochs = 2000\n",
    "model = create_model()\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5, beta_2=0.99)\n",
    "\n",
    "checkpoint_name = f'{task}_cnn_{model_type}_fold{fold_index}'\n",
    "cur_model_dir = model_dir / checkpoint_name\n",
    "cur_model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "plot_callback = PlotCallback(n_step=3)\n",
    "with tf.device('/GPU:0'):\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction=tf.keras.losses.Reduction.SUM),\n",
    "        optimizer=optimizer,\n",
    "        metrics=BalancedSparseCategoricalAccuracy(),\n",
    "    )\n",
    "    \n",
    "    mode = 'max'\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        batch_size=8, epochs=2000, shuffle=True,\n",
    "        validation_data=test_dataset,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                patience=20, \n",
    "                #monitor='val_sparse_categorical_accuracy',\n",
    "                monitor='val_balanced_sparse_categorical_accuracy',\n",
    "                mode=mode\n",
    "            ),\n",
    "            plot_callback,\n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                str(cur_model_dir / (checkpoint_name + '.model')),\n",
    "                monitor='val_balanced_sparse_categorical_accuracy', \n",
    "#                 monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True,\n",
    "                mode=mode, \n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "plot_callback.fig.tight_layout()\n",
    "plot_callback.fig.savefig(str(cur_model_dir / (checkpoint_name + '.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_data = []\n",
    "# model = create_model()\n",
    "# model.load_weights(str(cur_model_dir / (checkpoint_name + '.model')))\n",
    "# model.compile()\n",
    "\n",
    "results = {}\n",
    "for target_name, dataset in zip(['train', 'test'], [train_dataset, test_dataset]):\n",
    "    pred_logits = model.predict(dataset)\n",
    "    pred_labels = tf.argmax(tf.nn.softmax(pred_logits, axis=1), axis=1)\n",
    "\n",
    "    truth_labels = []\n",
    "    for batch in dataset:\n",
    "        truth_labels.extend(batch[1].numpy())\n",
    "    metric = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(\n",
    "        tf.convert_to_tensor(np.array(truth_labels).astype(np.int32)), \n",
    "        tf.convert_to_tensor(pred_logits.astype(np.float32))\n",
    "    )).numpy()\n",
    "\n",
    "    truth_labels = np.array(sound_events).take(truth_labels)\n",
    "    pred_labels = np.array(sound_events).take(pred_labels)\n",
    "    \n",
    "    agg_df = pd.crosstab(\n",
    "        pd.Series(truth_labels, name='Truth'),\n",
    "        pd.Series(pred_labels, name='Prediction'),\n",
    "    )\n",
    "    agg_df = agg_df.reindex(columns=sound_events, index=sound_events, fill_value=0)\n",
    "    display(target_name)\n",
    "    display(agg_df)\n",
    "    \n",
    "    accuracy = {}\n",
    "    for name in sound_events:\n",
    "        mask = truth_labels == name\n",
    "        accuracy[name] = accuracy_score(truth_labels[mask], pred_labels[mask]) \n",
    "    accuracy['Metric'] = metric\n",
    "    accuracy_data.append(pd.Series(accuracy, name=target_name))\n",
    "    \n",
    "    results[target_name] = {\n",
    "        'Prediction': pd.DataFrame({\n",
    "            'Prediction': pred_labels,\n",
    "            'Truth': truth_labels,\n",
    "        }),\n",
    "        'Agg': agg_df,\n",
    "        'Accuracy': accuracy_data,\n",
    "    }\n",
    "accuracy_df = pd.DataFrame(accuracy_data)\n",
    "accuracy_df['Mean'] = accuracy_df.mean(axis=1)\n",
    "display(accuracy_df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle as pickle\n",
    "with open(cur_model_dir / f'result_metric.pickle', 'wb+') as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
