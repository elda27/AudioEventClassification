{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 12.910117    1.2321125 -18.948282   26.127281   -2.4666774 -22.519981\n",
      "    6.820009   17.862968   -5.7939076   7.2299757]\n",
      " [ 12.910117    1.2321125 -18.948282   26.127281   -2.4666774 -22.519981\n",
      "    6.820009   17.862968   -5.7939076   7.2299757]\n",
      " [ 12.910117    1.2321125 -18.948282   26.127281   -2.4666774 -22.519981\n",
      "    6.820009   17.862968   -5.7939076   7.2299757]\n",
      " [ 12.910117    1.2321125 -18.948282   26.127281   -2.4666774 -22.519981\n",
      "    6.820009   17.862968   -5.7939076   7.2299757]], shape=(4, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import functools\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.signal import shape_ops\n",
    "import numpy as np\n",
    "\n",
    "def round_even(x):\n",
    "    if x % 2 == 0:\n",
    "        return x + 1\n",
    "    else:\n",
    "        return x + 2\n",
    "    \n",
    "class ConvRegressor(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, filters, kernel_size, \n",
    "        conv_type=tf.keras.layers.Conv2D, activation=tf.nn.relu, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.conv_type = conv_type\n",
    "        self.convs = []\n",
    "        for n_filter in filters:\n",
    "            self.convs.append(\n",
    "                conv_type(n_filter, round_even(kernel_size), strides=2, padding='SAME', activation=activation, **kwargs)\n",
    "            )\n",
    "            self.convs.append(conv_type(n_filter, kernel_size, padding='SAME', activation=activation, **kwargs))\n",
    "        self.convs.append(tf.keras.layers.Conv2D(n_filter, kernel_size, padding='SAME'))\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, x, training=False):\n",
    "        y = x\n",
    "        for conv in self.convs:\n",
    "            y = conv(y, training=training)\n",
    "        return y\n",
    "\n",
    "class LogmelSpectrumLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_mels=128, window_size=2048, hop_size=512, n_fft=2048, window=None, sampling_rate=44.1e3, fmin=0.0, fmax=22050, pad_end=False):\n",
    "        super().__init__(dynamic=True)\n",
    "        self.n_mels = n_mels\n",
    "        self.window_size = window_size\n",
    "        self.hop_size = hop_size\n",
    "        self.n_fft = n_fft\n",
    "        self.pad_end = pad_end\n",
    "\n",
    "        self.sampling_rate = sampling_rate \n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "\n",
    "        if window is None:\n",
    "            self.window = functools.partial(tf.signal.hann_window, periodic=False)\n",
    "        else:\n",
    "            self.window = window\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = tf.TensorShape(input_shape).as_list()\n",
    "        frame_axis = input_shape[1]\n",
    "        frame_step = self.hop_size\n",
    "        frame_length = self.window_size\n",
    "        num_frames = None\n",
    "        \n",
    "        \n",
    "        if frame_step is not None and self.pad_end:\n",
    "            # Double negative is so that we round up.\n",
    "            num_frames = max(0, -(-frame_axis // frame_step))\n",
    "        elif frame_step is not None and frame_length is not None:\n",
    "            num_frames = max(\n",
    "              0, (frame_axis - frame_length + frame_step) // frame_step)\n",
    "        return tf.TensorShape([input_shape[0], num_frames, self.n_mels, input_shape[-1]])\n",
    "    \n",
    "    def get_config(self):\n",
    "        return dict(\n",
    "            n_mels=self.n_mels.numpy(), \n",
    "            window_size=self.window_size.numpy(), \n",
    "            hop_size=self.hop_size.numpy(), \n",
    "            n_fft=self.n_fft.numpy(), \n",
    "            window=self.window.__name__ if callable(self.window) else self.window,\n",
    "            sampling_rate=self.sampling_rate.numpy(), \n",
    "            fmin=self.fmin.numpy(), fmax=self.fmax.numpy(),\n",
    "            pad_end=self.pad_end.numpy()\n",
    "        )\n",
    "    \n",
    "    def call(self, xs, training=False):\n",
    "        n_batch, _, n_channel = tf.shape(xs)\n",
    "        xs = tf.reshape(\n",
    "            tf.transpose(xs, (0, 2, 1)), \n",
    "            (-1, tf.shape(xs)[1])\n",
    "        )\n",
    "        stfts = tf.signal.stft(\n",
    "            xs, frame_length=self.window_size,\n",
    "            frame_step=self.hop_size,\n",
    "            fft_length=self.n_fft,\n",
    "            pad_end=False\n",
    "        )\n",
    "        spectrum = tf.square(tf.abs(stfts))\n",
    "        mel_bank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            self.n_mels, self.n_fft // 2 + 1, \n",
    "            self.sampling_rate, self.fmin, self.fmax\n",
    "        )\n",
    "\n",
    "        mel_spectrum = tf.math.log(\n",
    "            tf.tensordot(spectrum, mel_bank, 1) + 1e-8\n",
    "        )\n",
    "        \n",
    "        _, h, w = tf.shape(mel_spectrum)\n",
    "        return tf.transpose(\n",
    "            tf.reshape(mel_spectrum, (n_batch, n_channel, h, w)),\n",
    "            (0, 2, 3, 1)\n",
    "        )\n",
    "    \n",
    "class WavegramCNN(tf.keras.Model):\n",
    "    def __init__(self, base_net, n_wavegram_ch=3, kernel_size=7, gate_kernel_size=11, strides=3, gate_strides=5, activation=tf.nn.relu, **logmel_kwargs):\n",
    "        super().__init__(dynamic=True)\n",
    "        n_mels = logmel_kwargs.get('n_mels', 128)\n",
    "        self.n_wavegram_ch = n_wavegram_ch\n",
    "        \n",
    "        self.wavegram_net = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv1D(n_mels // 8, kernel_size=gate_kernel_size, strides=gate_strides, activation=activation),\n",
    "            \n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Conv1D(n_mels // 4, kernel_size=kernel_size, dilation_rate=2, strides=1, activation=activation),\n",
    "            tf.keras.layers.Conv1D(n_mels // 4, kernel_size=kernel_size, dilation_rate=1, strides=strides, activation=activation),\n",
    "\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Conv1D(n_mels // 2, kernel_size=kernel_size, dilation_rate=2, strides=1, activation=activation),\n",
    "            tf.keras.layers.Conv1D(n_mels // 2, kernel_size=kernel_size, dilation_rate=1, strides=strides, activation=activation),\n",
    "\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Conv1D(n_mels, kernel_size=kernel_size, dilation_rate=2, strides=1, activation=activation),\n",
    "            tf.keras.layers.Conv1D(n_mels, kernel_size=kernel_size, dilation_rate=1, strides=strides, activation=activation),\\\n",
    "        ])\n",
    "        self.logmel_layer = LogmelSpectrumLayer(**logmel_kwargs)\n",
    "        self.cnn = base_net\n",
    "    \n",
    "#     @tf.function\n",
    "    def call(self, x, training=False):\n",
    "#         x = x / tf.reduce_max(x, axis=(1, 2), keepdims=True)\n",
    "        logmel  = self.logmel_layer(x, training=training)\n",
    "        wavegram = self.wavegram_net(x, training=training)\n",
    "        \n",
    "        batch_size = tf.shape(x)[0]\n",
    "        n_frames = tf.shape(logmel)[1]\n",
    "        n_filters = tf.shape(wavegram)[1]\n",
    "        n_wavegram_dim = n_frames * self.n_wavegram_ch\n",
    "        wavegram_offset = (n_filters - n_wavegram_dim) // 2\n",
    "        \n",
    "        wavegram = tf.transpose(\n",
    "            tf.reshape(\n",
    "                wavegram[:, wavegram_offset:wavegram_offset+n_wavegram_dim, :],\n",
    "                (batch_size, n_frames, self.n_wavegram_ch, -1) # N, T, C, F\n",
    "            ), (0, 1, 3, 2) # N, T, F, C\n",
    "        )\n",
    "\n",
    "        return self.cnn(tf.concat([wavegram, logmel], axis=-1), training=training)\n",
    "\n",
    "layer = WavegramCNN(tf.keras.Sequential([tf.keras.layers.Flatten(), tf.keras.layers.Dense(10)]))\n",
    "t = layer(tf.zeros((4, 32000, 2)))\n",
    "# print(layer.compute_output_shape((4, 32000, 2)))\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from libs.layers import resnet\n",
    "from libs.layers import cbam_resnet\n",
    "from libs.layers import conv_attention_resnet\n",
    "\n",
    "ResNet = resnet.ResNet34\n",
    "ResNetCBAM = cbam_resnet.ResNetCBAM34\n",
    "AttentionResNet = conv_attention_resnet.AttentionResNet34\n",
    "AxialAttentionResNet = conv_attention_resnet.AxialAttentionResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "fold_index = 0\n",
    "task = 'home'\n",
    "model_type = 'attention'\n",
    "\n",
    "model_dir = './model'\n",
    "data_dir = './data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.experimental.set_memory_growth(\n",
    "#     tf.config.list_physical_devices('GPU')[0], allow_memory_growth\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "model_dir = Path(model_dir)\n",
    "data_dir = Path(data_dir)\n",
    "model_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033b123c24f3462fa8755767ce24f576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load training setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from libs.misc import wavio\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "root_dir = data_dir / 'evaluation_setup'\n",
    "\n",
    "data_cache = {}\n",
    "\n",
    "def get_annotation(task, fold_index, target):\n",
    "    df = pd.read_csv(\n",
    "        root_dir / f'{task}_fold{fold_index+1}_{target}.txt', sep='\\t', \n",
    "        header=None, names=['file', 'class', 'start', 'end', 'event']\n",
    "    )\n",
    "    df['id'] = df['file'].apply(lambda x: Path(x).stem)\n",
    "    return df\n",
    "\n",
    "def load_dataset(target):\n",
    "    if target not in data_cache:\n",
    "        df = get_annotation(task, fold_index, target)\n",
    "        wav_dict = {}\n",
    "        for file in tqdm(df['file'].unique()):\n",
    "            wav_dict[Path(file).stem] = wavio.readwav(str(data_dir / file))\n",
    "        data_cache[target] = (df, wav_dict)\n",
    "        return df, wav_dict\n",
    "    else:\n",
    "        return data_cache[target]\n",
    "df, wav_dict = load_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan', '(object) rustling', '(object) snapping', 'cupboard', 'cutlery', 'dishes', 'drawer', 'glass jingling', 'object impact', 'people walking', 'washing dishes', 'water tap running']\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "sound_events = ['nan']\n",
    "\n",
    "for fold, task_name in product([0,1,2,3], ['train', 'evaluate', 'test']):\n",
    "    sound_events.extend(get_annotation('home', fold, task_name)['event'].unique())\n",
    "sound_events = list(filter(lambda x: x != 'nan', np.unique(sound_events)))\n",
    "sound_events = ['nan'] + sound_events\n",
    "print(sound_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "n_augmentation = 5\n",
    "perturbation = (0.0, 0.05)\n",
    "\n",
    "def parse_wave(series, wav_dict, start=0.0, end=5.0, duration=5.0):    \n",
    "    result = series.to_dict()\n",
    "    sr, bw, audio = wav_dict[series['id']]\n",
    "    \n",
    "    data = np.zeros((int(duration * sr), 2), dtype=np.float32)\n",
    "    mask = np.zeros((int(duration * sr), 1), dtype=np.bool)\n",
    "    \n",
    "    start = int(start * sr)\n",
    "    end = int(end * sr)\n",
    "    data[start:end] = audio[start:end]\n",
    "    mask[start:end] = True\n",
    "    \n",
    "    result['id'] = series['id']\n",
    "    result['start_index'] = max(start, 0)\n",
    "    result['end_index'] = min(end, len(audio))\n",
    "    result['sr'] = sr\n",
    "    result['bw'] = bw\n",
    "    result['audio'] = data\n",
    "    result['mask'] = mask\n",
    "    \n",
    "    return pd.Series(result)\n",
    "\n",
    "_id = df.loc[0, 'id']\n",
    "sr = wav_dict[_id][0]\n",
    "# display(Audio(wav_dict[_id][2][:, 0], rate=sr))\n",
    "# display(Audio(\n",
    "#     parse_wave(df.loc[0], wav_dict=wav_dict)['audio'][:, 0], rate=sr\n",
    "# ))\n",
    "# audio_df = df.apply(partial(parse_wave, wav_dict=wav_dict, window_size=5.0, hop_size=1.25), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import librosa\n",
    "import joblib\n",
    "import random \n",
    "\n",
    "n_mels = 128\n",
    "n_sampling=4096\n",
    "hop_length = n_sampling // 4\n",
    "window='hann'\n",
    "pad='constant'\n",
    "max_time = 1.0\n",
    "batch_size = 2\n",
    "\n",
    "def preprocess(wav, sampling_rate):\n",
    "    return np.concatenate([\n",
    "        mono_preprocess(wav[..., 0], sampling_rate)[..., np.newaxis],\n",
    "        mono_preprocess(wav[..., 1], sampling_rate)[..., np.newaxis],\n",
    "    ], axis=-1)\n",
    "\n",
    "def mono_preprocess(wav, sampling_rate):\n",
    "    mag = librosa.feature.melspectrogram(\n",
    "        wav, sr=sampling_rate, hop_length=hop_length, n_mels=n_mels,\n",
    "        fmin=0.0, fmax=20e3,\n",
    "    )\n",
    "    logmag = np.log(mag + 1e8)\n",
    "    return logmag\n",
    "\n",
    "def normalize_time(audio_df, max_time):\n",
    "    results = []\n",
    "    for audio, sr in zip(audio_df['audio'], audio_df['sr']):\n",
    "        max_len = int(sr * max_time)\n",
    "\n",
    "        pos = min(len(audio), max_len)\n",
    "        result = np.zeros((max_len, 2), np.float32)\n",
    "        result[:pos, :] = audio[:pos]\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_dataset(target):\n",
    "    df, wav_dict = load_dataset(target)\n",
    "    encoding_dict = {event: i for i, event in enumerate(sound_events)}\n",
    "    \n",
    "    def yield_wave():\n",
    "        def _parse_wave(series):\n",
    "            start = random.uniform(0.0, 0.1 * max_time)\n",
    "            end = random.uniform(0.1 * max_time, max_time)\n",
    "            end = end if (max_time - start) > (start + end) else (max_time - start)\n",
    "            return parse_wave(series, wav_dict, start=start, end=end, duration=max_time)\n",
    "            \n",
    "        for i in df.index:\n",
    "            series = _parse_wave(df.loc[i])\n",
    "            event = encoding_dict[series['event']]\n",
    "            yield series['audio'], series['mask'], event\n",
    "    return yield_wave\n",
    "    \n",
    "def get_tf_dataset(target, batch_size=32, shuffle=False, **kwargs):\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        get_dataset(target, **kwargs),\n",
    "        output_types=(tf.float32, tf.bool, tf.int32)\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size, drop_remainder=shuffle)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_tf_dataset('train', batch_size=batch_size, shuffle=True)\n",
    "test_dataset = get_tf_dataset('evaluate', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class PlotCallback(tf.keras.callbacks.Callback):\n",
    "    is_higher_better = {\n",
    "        'accuracy'\n",
    "    }\n",
    "    is_linear = {\n",
    "        'accuracy',\n",
    "        'sparse_categorical_accuracy',\n",
    "    }\n",
    "    def __init__(self, targets=None, n_step=1):\n",
    "        super().__init__()\n",
    "        self.fig = None\n",
    "        self.axes = None\n",
    "        self.axes_index = {}\n",
    "        self.n_step = n_step\n",
    "        self.targets = targets\n",
    "        self.epochs = []\n",
    "        self.history = defaultdict(list)\n",
    "\n",
    "    def plot_and_display(self):\n",
    "        for ax in self.axes.flat:\n",
    "            ax.clear()\n",
    "        for i, (label, values) in enumerate(self.history.items()):\n",
    "            if any(name in label for name in self.is_higher_better):\n",
    "                get_best_value = np.amax\n",
    "            else:\n",
    "                get_best_value = np.amin\n",
    "            \n",
    "            if label.startswith('val_'):\n",
    "                _label = label[4:]\n",
    "            else:\n",
    "                _label = label\n",
    "            \n",
    "            ax = self.axes.flat[self.axes_index[_label]]\n",
    "            ax.plot(self.epochs, values, label=label, color=f'C{i}')\n",
    "            best_value = get_best_value(values)\n",
    "            ax.axhline(best_value, linestyle='--', color=f'C{i}')\n",
    "            ax.text(0.0, best_value, f'{best_value:.3f}')\n",
    "            \n",
    "            if _label not in self.is_linear:\n",
    "                ax.set_yscale('log')\n",
    "\n",
    "        if self.epochs[-1] == 0:\n",
    "            self.fig.legend()\n",
    "\n",
    "        io = BytesIO()\n",
    "        self.fig.savefig(io, format='png')\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display_png(Image(io.getvalue()))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch == 0:\n",
    "            self.fig, self.axes = plt.subplots(len(logs) // 2, 1, figsize=(8, 4 * len(logs) // 2))\n",
    "            self.axes_index = {}\n",
    "            for label in logs:\n",
    "                if label.startswith('val_'):\n",
    "                    _label = label[4:]\n",
    "                else:\n",
    "                    _label = label\n",
    "                if _label not in self.axes_index:\n",
    "                    self.axes_index[_label] = len(self.axes_index)\n",
    "\n",
    "        for key, value in logs.items():\n",
    "            self.history[key].append(value)\n",
    "\n",
    "        self.epochs.append(epoch)\n",
    "        if (epoch % self.n_step) == 0:\n",
    "            self.plot_and_display()\n",
    "\n",
    "class BalancedSparseCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "    def __init__(self, name='balanced_sparse_categorical_accuracy', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_flat = y_true\n",
    "        if y_true.shape.ndims == y_pred.shape.ndims:\n",
    "            y_flat = tf.squeeze(y_flat, axis=[-1])\n",
    "        y_true_int = tf.cast(y_flat, tf.int32)\n",
    "\n",
    "        cls_counts = tf.math.bincount(y_true_int)\n",
    "        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n",
    "        weight = tf.gather(cls_counts, y_true_int)\n",
    "        return super().update_state(y_true, y_pred, sample_weight=weight)\n",
    "    \n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    return tf.keras.Sequential([\n",
    "        ConvRegressor([8, 16, 32, 64, ], kernel_size=7),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "def create_resnet_cnn_model():\n",
    "    return tf.keras.Sequential([\n",
    "        ResNet(kernel_size=5),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "def create_cbam_model():\n",
    "    return tf.keras.Sequential([\n",
    "        ResNetCBAM(kernel_size=5),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "def create_attention_model():\n",
    "    return tf.keras.Sequential([\n",
    "        AttentionResNet(kernel_size=1),\n",
    "        tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "def create_axial_attention_model():\n",
    "    return tf.keras.Sequential([\n",
    "        AxialAttentionResNet(kernel_size=1),\n",
    "        tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Conv2D(1024, kernel_size=7, strides=2, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(sound_events)),\n",
    "    ])\n",
    "\n",
    "model_type = 'cnn'\n",
    "if model_type == 'cnn':\n",
    "    learning_rate = 1e-5\n",
    "    create_model = create_cnn_model\n",
    "elif model_type == 'resnet':\n",
    "    learning_rate = 1e-5\n",
    "    create_model = create_resnet_cnn_model\n",
    "elif model_type == 'cbam':\n",
    "    learning_rate = 1e-4\n",
    "    create_model = create_cbam_model\n",
    "elif model_type == 'attention':\n",
    "    create_model = create_attention_model\n",
    "    learning_rate = CustomSchedule(128)\n",
    "elif model_type == 'axial-attention':\n",
    "    learning_rate = 1e-4\n",
    "    create_model = create_axial_attention_model\n",
    "else:\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# import librosa.display\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.io import wavfile \n",
    "# from pathlib import Path\n",
    "\n",
    "# output_dir = Path('audio')\n",
    "# output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# logmel_layer = LogmelSpectrumLayer()\n",
    "# for i, (audio, mask, event) in tqdm(enumerate(train_dataset.unbatch().as_numpy_iterator())):\n",
    "#     logmel_spec = logmel_layer(tf.expand_dims(audio, axis=0)).numpy()\n",
    "    \n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "#     for j in range(2):\n",
    "#         ax = axes.flat[j]\n",
    "#         mappable = librosa.display.specshow(\n",
    "#             logmel_spec[0, ..., j].T,\n",
    "#             sr=44100, hop_length=512,\n",
    "#             x_axis='time', y_axis='mel',\n",
    "#             fmin=0.0, fmax=20.0e3,\n",
    "#             ax=ax, # cmap='inferno'\n",
    "#         )\n",
    "#         mappable.set_clim(-35.0, 35.0)\n",
    "#     colorbar = fig.colorbar(mappable)\n",
    "#     plt.close(fig)\n",
    "#     fig.savefig(str(output_dir / f'{i:04d}_{sound_events[event]}.png'))\n",
    "#     wavfile.write(str(output_dir / f'{i:04d}_{sound_events[event]}.wav'), 44100, audio.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "    155/Unknown - 5s 35ms/step - loss: 4.7111 - balanced_sparse_categorical_accuracy: 0.2301"
     ]
    }
   ],
   "source": [
    "import IPython \n",
    "from collections import defaultdict \n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import time\n",
    "import seaborn as sns\n",
    "from io import BytesIO\n",
    "import imageio\n",
    "from IPython.display import Image, display_png, clear_output\n",
    "\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "if 'model' in globals():\n",
    "    del model\n",
    "epochs = 2000\n",
    "base_net = create_model()\n",
    "base_net.add(tf.keras.layers.Activation('softmax'))\n",
    "model = WavegramCNN(base_net)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.5, beta_2=0.99)\n",
    "\n",
    "checkpoint_name = f'{task}_cnn_{model_type}_fold{fold_index}'\n",
    "cur_model_dir = model_dir / checkpoint_name\n",
    "cur_model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "plot_callback = PlotCallback(n_step=3)\n",
    "with tf.device('/GPU:0'):\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=False, reduction=tf.keras.losses.Reduction.SUM),\n",
    "        optimizer=optimizer,\n",
    "        metrics=BalancedSparseCategoricalAccuracy(),\n",
    "#         options=tf.distribute.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "    )\n",
    "    \n",
    "    mode = 'min'\n",
    "    model.fit(\n",
    "        train_dataset.map(lambda *vars_list: (vars_list[0], vars_list[-1])),\n",
    "        batch_size=batch_size, epochs=2000, shuffle=True,\n",
    "        validation_data=test_dataset.map(lambda *vars_list: (vars_list[0], vars_list[-1])),\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                patience=50, \n",
    "                monitor='val_loss',\n",
    "                #monitor='val_balanced_sparse_categorical_accuracy',\n",
    "                mode=mode\n",
    "            ),\n",
    "            plot_callback,\n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                str(cur_model_dir / (checkpoint_name + '.model')),\n",
    "                monitor='val_loss',\n",
    "                #monitor='val_balanced_sparse_categorical_accuracy', \n",
    "                save_best_only=True,\n",
    "                save_weights_only=True,\n",
    "                mode=mode, \n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "plot_callback.fig.tight_layout()\n",
    "plot_callback.fig.savefig(str(cur_model_dir / (checkpoint_name + '.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_data = []\n",
    "model = create_model()\n",
    "model.load_weights(str(cur_model_dir / (checkpoint_name + '.model')))\n",
    "model.compile()\n",
    "\n",
    "results = {}\n",
    "for target_name, dataset in zip(['train', 'test'], (train_dataset, test_dataset)):\n",
    "    pred_logits = model.predict(\n",
    "        dataset.map(lambda audios, norm_audios, labels: (audios, labels))\n",
    "    )\n",
    "    pred_labels = tf.argmax(tf.nn.softmax(pred_logits, axis=1), axis=1)\n",
    "    \n",
    "    audio = []\n",
    "    truth_labels = []\n",
    "    for batch in dataset:\n",
    "        audio.extend(batch[1].numpy())\n",
    "        truth_labels.extend(batch[2].numpy())\n",
    "    metric = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(\n",
    "        tf.convert_to_tensor(np.array(truth_labels).astype(np.int32)), \n",
    "        tf.convert_to_tensor(pred_logits.astype(np.float32))\n",
    "    )).numpy()\n",
    "\n",
    "    truth_labels = np.array(sound_events).take(truth_labels)\n",
    "    pred_labels = np.array(sound_events).take(pred_labels)\n",
    "    \n",
    "    agg_df = pd.crosstab(\n",
    "        pd.Series(truth_labels, name='Truth'),\n",
    "        pd.Series(pred_labels, name='Prediction'),\n",
    "    )\n",
    "    agg_df = agg_df.reindex(columns=sound_events, index=sound_events, fill_value=0)\n",
    "    display(target_name)\n",
    "    display(agg_df)\n",
    "    \n",
    "    accuracy = {}\n",
    "    for name in sound_events:\n",
    "        mask = truth_labels == name\n",
    "        accuracy[name] = accuracy_score(truth_labels[mask], pred_labels[mask]) \n",
    "    accuracy['Metric'] = metric\n",
    "    accuracy_data.append(pd.Series(accuracy, name=target_name))\n",
    "    \n",
    "    results[target_name] = {\n",
    "        'Audio': None if save_without_train and target_name == 'train' else audio,\n",
    "        'Prediction': pd.DataFrame({\n",
    "            'Prediction': pred_labels,\n",
    "            'Truth': truth_labels,\n",
    "        }),\n",
    "        'Agg': agg_df,\n",
    "        'Accuracy': accuracy_data,\n",
    "    }\n",
    "accuracy_df = pd.DataFrame(accuracy_data)\n",
    "accuracy_df['Mean'] = accuracy_df.mean(axis=1)\n",
    "display(accuracy_df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle as pickle\n",
    "with open(cur_model_dir / f'result_metric.pickle', 'wb+') as fp:\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_without_train and 'train' == 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
